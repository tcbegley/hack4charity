{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a classifier for personal attacks with the Wikipedia Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import urllib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# download annotated comments and annotations\n",
    "\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7554634' \n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7554637' \n",
    "\n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# panda-fy the data\n",
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LogReg in SKLearn doesn't support continuous vars, so use a 'voting' methodology to determine classification\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove newline and tab tokens\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rev_id\n",
       "801279             Iraq is not good  ===  ===  USA is bad   \n",
       "2702703      ____ fuck off you little asshole. If you wan...\n",
       "4632658         i have a dick, its bigger than yours! hahaha\n",
       "6545332      == renault ==  you sad little bpy for drivin...\n",
       "6545351      == renault ==  you sad little bo for driving...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.query('attack')['comment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.955\n"
     ]
    }
   ],
   "source": [
    "# fit a Log Reg with character ngrams between 1 and 5 (takes a while)\n",
    "\n",
    "# note that the data already has train/test labels\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features = 10000, ngram_range = (1,5), analyzer='word', norm='l2')),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "auc = roc_auc_score(test_comments['attack'], clf.predict_proba(test_comments['comment'])[:, 1])\n",
    "print('Test ROC AUC: %.3f' %auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False], dtype=bool)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True], dtype=bool)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment with obfuscations\n",
    "clf.predict(['You are a f** cu*t!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORKS ON OBFUSCATED CHARACTERS !!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform the comments to tfidf\n",
    "\n",
    "tfidf_v =  TfidfVectorizer(max_features = 10000, ngram_range = (1,5), analyzer='word', norm='l2')\n",
    "out_spars = tfidf_v.fit_transform(comments['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "params = {'C': [1, 10, 100, 1000], 'penalty': ['l1','l2']}\n",
    "\n",
    "gscv = GridSearchCV(clf,cv=4,param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.fit(out_spars,comments['attack'])\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  5.61631161,   5.51555151,  10.01550138,  10.03600347,\n",
       "         50.25377482,  14.96274614,  86.61616087,  55.14251369]),\n",
       " 'mean_score_time': array([ 0.0225023 ,  0.02600265,  0.01900196,  0.02100217,  0.02125216,\n",
       "         0.02050203,  0.02050203,  0.02025205]),\n",
       " 'mean_test_score': array([ 0.94428813,  0.94051647,  0.93816026,  0.9417593 ,  0.92476524,\n",
       "         0.93384485,  0.92048436,  0.92488607]),\n",
       " 'mean_train_score': array([ 0.94892   ,  0.94751318,  0.96419653,  0.9597977 ,  0.97028989,\n",
       "         0.96686633,  0.9710609 ,  0.97002521]),\n",
       " 'param_C': masked_array(data = [1 1 10 10 100 100 1000 1000],\n",
       "              mask = [False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_penalty': masked_array(data = ['l1' 'l2' 'l1' 'l2' 'l1' 'l2' 'l1' 'l2'],\n",
       "              mask = [False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'C': 1, 'penalty': 'l1'},\n",
       "  {'C': 1, 'penalty': 'l2'},\n",
       "  {'C': 10, 'penalty': 'l1'},\n",
       "  {'C': 10, 'penalty': 'l2'},\n",
       "  {'C': 100, 'penalty': 'l1'},\n",
       "  {'C': 100, 'penalty': 'l2'},\n",
       "  {'C': 1000, 'penalty': 'l1'},\n",
       "  {'C': 1000, 'penalty': 'l2'}),\n",
       " 'rank_test_score': array([1, 3, 4, 2, 7, 5, 8, 6]),\n",
       " 'split0_test_score': array([ 0.94466117,  0.94089826,  0.93710084,  0.94086374,  0.92208375,\n",
       "         0.93268202,  0.91731971,  0.92222184]),\n",
       " 'split0_train_score': array([ 0.94870939,  0.94763916,  0.96465931,  0.95990656,  0.97098864,\n",
       "         0.96745572,  0.97170213,  0.97068944]),\n",
       " 'split1_test_score': array([ 0.94459212,  0.94127801,  0.9378258 ,  0.94258984,  0.92422412,\n",
       "         0.93323437,  0.91956364,  0.92456934]),\n",
       " 'split1_train_score': array([ 0.9490201 ,  0.9475586 ,  0.96414145,  0.95991806,  0.97045928,\n",
       "         0.967122  ,  0.97126483,  0.97018309]),\n",
       " 'split2_test_score': array([ 0.94500259,  0.94130848,  0.93947868,  0.94272398,  0.92680822,\n",
       "         0.93523218,  0.9233903 ,  0.92663559]),\n",
       " 'split2_train_score': array([ 0.94858399,  0.94689237,  0.96358991,  0.95928607,  0.96944729,\n",
       "         0.96596048,  0.9702183 ,  0.96918261]),\n",
       " 'split3_test_score': array([ 0.9428966 ,  0.93858105,  0.9382358 ,  0.94085966,  0.92594511,\n",
       "         0.93423097,  0.92166408,  0.92611773]),\n",
       " 'split3_train_score': array([ 0.94936651,  0.94796258,  0.96439545,  0.96008009,  0.97026433,\n",
       "         0.96692712,  0.97105836,  0.97004569]),\n",
       " 'std_fit_time': array([  2.4009852 ,   0.8962689 ,   0.13418209,   1.0345699 ,\n",
       "         22.62953461,   0.16211551,   7.46983854,  17.46203433]),\n",
       " 'std_score_time': array([ 0.00610388,  0.00616493,  0.00100017,  0.00308253,  0.00334502,\n",
       "         0.00206185,  0.00111814,  0.00082919]),\n",
       " 'std_test_score': array([ 0.00081828,  0.00112902,  0.00086287,  0.00089886,  0.00180618,\n",
       "         0.0009745 ,  0.00227481,  0.00171583]),\n",
       " 'std_train_score': array([ 0.00030276,  0.000389  ,  0.00039521,  0.00030325,  0.00055398,\n",
       "         0.0005561 ,  0.00053915,  0.00054234])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.cv_results_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
